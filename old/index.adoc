= The AI Backbone: Breaking the Cycle of Credential Sprawl
:role: Product Concept
:audience: Platform Engineers & Architects
:description: Understanding the critical role of Data Connections and Storage Classes in the AI lifecycle.

[.lead]
*Data is the fuel for AI. But without the right plumbing, it's just a fire hazard.*

In a mature DevOps environment, no platform engineer would allow a developer to hardcode database passwords directly into their application source code. You use secrets management. You use environment abstraction. You use distinct storage classes for performance.

Yet, walk into a typical Data Science team, and you will see the "Anti-Pattern" everywhere: AWS Access Keys hardcoded into Jupyter Notebook cells, massive datasets duplicated across twenty different local drives, and `boto3` scripts that break the moment you try to move them from a laptop to a production cluster.

This is **Credential Sprawl**. It creates security risks, locks you into specific environments, and makes collaboration impossible.

[NOTE]
.The Core Sales Objection
====
*"Why can't our data scientists just use standard S3 libraries and hardcode their keys? It's faster."*

It is faster for *one* person, once. It is a disaster for an enterprise. Hardcoding keys means you cannot rotate credentials without breaking code. It means you cannot move from Dev to Prod without rewriting scripts. It means you have zero governance over where your data is going.
====

== The Solution: The RHOAI Connectivity Layer

**Red Hat OpenShift AI (RHOAI) 3** solves this by decoupling **Data** from **Compute**.

Instead of embedding storage details into the workload, RHOAI uses two architectural primitives to abstract the infrastructure:

1.  **Data Connections:** A secure, Kubernetes-native way to inject credentials and endpoints into Workbenches and Model Servers without the user ever seeing the raw keys.
2.  **Storage Classes (PVCs):** A dynamic system for provisioning high-performance, persistent disk storage that survives workbench shutdowns and enables real-time collaboration.

image::images/rhoai-data-connectivity-architecture.png

== Three Pillars of Value

By implementing the RHOAI Storage Architecture, you deliver three capabilities that "manual scripting" cannot match:

=== 1. Security & Compliance
When a data scientist uses a **Data Connection**, they are not typing an Access Key. They are referencing a secure Kubernetes Secret managed by you, the Platform Engineer.

* **The Win:** You can rotate the underlying AWS or MinIO keys centrally.
* **The Benefit:** The data scientist's code never changes, and the secure credentials never appear in their notebook source control.

=== 2. Hybrid Portability
In a real-world AI factory, models are developed in a "Sandbox" (Dev), trained on a "Cluster" (Test), and deployed to "Edge" (Prod).

* **The Win:** RHOAI Data Connections use standard protocols (S3, URI, OCI) to create a consistent interface.
* **The Benefit:** The same training pipeline code runs in every environment. You simply swap the "Connection" reference from the *Dev Bucket* to the *Prod Bucket*. No code rewrites required.

=== 3. Velocity & Collaboration
Downloading a 500GB dataset to twenty different laptops is a waste of time and bandwidth.

* **The Win:** RHOAI leverages **ReadWriteMany (RWX)** Storage Classes.
* **The Mechanism:** A single "Golden Dataset" is mounted to a shared volume.
* **The Benefit:** The entire research team can mount that same volume to their independent workbenches simultaneously. They can explore, clean, and experiment on the data in real-time without duplication or network latency.

== Your Mission: Architect the Backbone

In this course, you will move beyond simple storage provisioning. You will architect the **data foundation** for RHOAI 3.

You will take on the role of a **Lead Platform Engineer** ensuring your data scientists can work securely and efficiently. You will execute the following technical workflow:

1.  **The Foundation:** Configure **Storage Classes** to support high-performance RWO (Personal) and collaborative RWX (Shared) workspaces.
2.  **The Gateway:** Create and manage **Data Connections** for S3 Object Storage and OCI Model Registries, abstracting the credentials from the users.
3.  **The Acceleration:** Implement **Pipeline Workspaces** and **Modelcars** (OCI) to speed up training handoffs and reduce model deployment times.

[IMPORTANT]
.Prerequisites
====
To successfully complete the hands-on sections of this course, you need:

* Access to a **Red Hat OpenShift AI 3** cluster.
* `cluster-admin` privileges (to configure Storage Classes and global connection types).
* An external Object Store (AWS S3 or MinIO) to verify connectivity.
====

*Ready to secure the flow? Let's start by defining the storage foundation.*