= The Storage Strategy: Architecting for AI Scale
:navtitle: The Storage Strategy
:imagesdir: ../images
:role: Product Concept
:audience: Platform Engineers & Architects
:description: Moving beyond connectivity to designing a high-performance, resilient AI storage layer.

[.lead]
*Connectivity is easy. Performance is engineering.*

In the early stages of AI adoption, the primary challenge is simply **access**: *"How do I connect my Jupyter Notebook to an S3 bucket?"*

But as you move from "Science Project" to "Production Service," the challenges shift dramatically. You are no longer moving 1GB CSV files; you are serving **70GB Large Language Models (LLMs)** to thousands of concurrent users.

At this scale, storage is no longer just a place to keep files—it becomes the **primary bottleneck** of your entire platform.

* **The Risk:** If every pod downloads a 50GB model on startup, you flood the network and stall your rollout.
* **The Cost:** If every team duplicates datasets to block storage, your cloud bill explodes.
* **The Failure:** If you rely on ephemeral storage for production serving, a single node reboot can take down your service for 20 minutes while it re-downloads assets.

**In this course, you will evolve from managing "Disks" to architecting "Strategies."**



== The Three Pillars of AI Storage

image::storage-conn.png[align="center", title="Architecting the AI Supply Chain: Velocity, Security, and Scale"]

We will replace the "One-Size-Fits-All" approach with a tiered strategy designed for specific AI workloads.

=== 1. The Velocity Tier (OCI Modelcars)
* **The Challenge:** Initialization Latency. Waiting 15 minutes for a model to download before a pod becomes "Ready."
* **The Solution:** **Boot-from-Registry.** By packaging models as OCI images (Modelcars), you leverage the cluster's native image puller.
* **The Outcome:** **Instant Scaling.** The underlying layers are cached on the node. Scaling from 1 replica to 50 takes seconds, not hours, because the data is already there.

=== 2. The Persistence Tier (Cluster Storage)
* **The Challenge:** The "Air-Gap" & Collaboration. How do you serve proprietary models in disconnected environments, or share a "Golden Dataset" with 50 researchers without making 50 copies?
* **The Solution:** **ReadWriteMany (RWX) & Retain Policies.** We will configure shared volumes that act as a central library for your teams.
* **The Outcome:** **Efficiency.** A single 1TB volume serves the entire organization, slashing storage costs and ensuring everyone is training on the exact same data version.

=== 3. The Abstraction Tier (Data Connections)
* **The Challenge:** Governance. Preventing hardcoded credentials and ensuring environment parity between Dev and Prod.
* **The Solution:** **Universal Data Connections.** We will use Kubernetes Secrets to inject connection details for S3 / OCI / URI storage types.
* **The Outcome:** **Portability.** The same code runs in the Sandbox and in Production without a single line change.

== Your Mission: The "AI Factory" Blueprint

You are not just learning to run `oc create secret`. You are learning to build the **Data Supply Chain** that powers the AI Factory.

In the upcoming modules, you will:

1.  **Analyze the Physics:** Understand why downloading models to `emptyDir` kills production stability.
2.  **Build the Highway:** Deploy **OCI Data Connections** to stream models instantly.
3.  **Secure the Vault:** Provision **Shared Storage** that supports air-gapped workflows.
4.  **Connect the Brain:** Wire up the external **Databases** required for RHOAI 3’s advanced metadata tracking.

[IMPORTANT]
.The Shift in Mindset
====
We are stopping the practice of treating models like "files." In RHOAI 3, we treat models like **software artifacts**—versioned, immutable, and cached.
====

*Ready to architect the solution? Let's examine the blueprint.* 