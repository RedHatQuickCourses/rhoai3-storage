= The Blueprint: Architecting Data Logistics
:navtitle: Architecture Overview
:imagesdir: ../images

*Theory is over. It is time to look at the machinery under the floorboards.*

In the previous module, we established that a Data Supply Chain produces **Velocity**, **Security**, and **Collaboration**. Now, we must examine the specific OpenShift AI (RHOAI) primitives that execute this vision.

As a Platform Engineer, you are not just managing hard drives; you are managing the lifecycle of data as it transitions from "Cold Object Storage" to "Hot Shared Memory."

== 1. The Universal Adapter: Connection Types vs. Data Connections

To achieve **Zero-Touch Security**, RHOAI separates the *definition* of a credential from the *usage* of a credential. This is handled by two distinct API objects.

=== The Contract: Connection Types (The Template)
Think of the **Connection Type** as the "Electrical Socket" on the wall. The Administrator defines the shape of the socket to ensure safety and standardization.

 * **What it does:** It creates a form in the RHOAI Dashboard requiring specific fields (e.g., "Endpoint", "Bucket", "Access Key").
 * **The Business Value:** **Standardization.** You ensure that every team connects to the Corporate Data Lake using the exact same protocol and parameters, preventing "snowflake" configurations.

=== The Key: Data Connections (The Instance)
Think of the **Data Connection** as the "Plug." It is the specific instance where a user provides their credentials to fit the socket.

 * **What it does:** It stores the sensitive values as a Kubernetes Secret and injects them into the Workbench as environment variables at runtime.
 * **The Business Value:** **Abstraction.** The Data Scientist's code acts against generic variables (like `AWS_S3_ENDPOINT`), meaning the same code works in Dev, Test, and Prod without modification.



== 2. The Logistics Channels: Supported Protocols

Not all data moves the same way. RHOAI provides three "Logistics Channels" (Protocols) to optimize for capacity, speed, or precision.

=== A. S3 Object Storage: The Warehouse (Capacity)
This is the default protocol for massive unstructured data (images, logs, documents).

 * **Usage:** Used for Data Lakes, Pipeline Artifacts, and standard Model Serving. 
 * **The "Sharp Edge":** When using on-premise object stores (like MinIO), you must often inject a **Bundle CA** to ensure the platform trusts your self-signed certificates.

=== B. OCI Registry: The Teleporter (Velocity)
This is the protocol for **Modelcars**. instead of downloading models as files, we package them as container images.

 * **Usage:** High-speed model inference and distribution.
 * **The Advantage:** It leverages the node's container image cache. If 10 users need the same "Granite 7B" model, the node downloads the layers *once*, and all 10 users start instantly. This produces massive **deduplication** and **startup velocity**.

=== C. URI: The Precision Link
Sometimes you do not want to expose an entire bucket; you only want to share a single file version.

 * **Usage:** Direct HTTP/HTTPS links to specific assets (e.g., `https://.../model-v1.onnx`).
 * **The Limit:** These are generally read-only and best used for fetching public or version-locked assets.

== 3. The Workspace: Designing Persistence

Once data arrives from the "Warehouse" (S3), it needs a place to live while it is being processed. This is your **Cluster Storage**.



|===
| Storage Type | The Analogy | The Technical Term | The Business Outcome

| **ReadWriteOnce (RWO)**
| The Private Notebook
| Block Storage (EBS, vSphere)
| **Isolation.** Fast, exclusive storage for a single user. Ideal for databases or personal scratchpads.

| **ReadWriteMany (RWX)**
| The Conference Room
| File Storage (CephFS, NFS, EFS)
| **Collaboration.** Allows multiple pods to mount the same volume simultaneously. Required for shared team folders and distributed training.
|===

[IMPORTANT]
.Critical Architecture Check
====
You must verify that your underlying storage provider supports **RWX**. If you attempt to create a shared workspace on infrastructure that only supports Block Storage (RWO), the claims will hang in a `Pending` state forever.
====

== 4. The Foundation: The Metadata Layer

In RHOAI 3, we have made a critical architectural shift to support the "Industrialized" scale.

 * **The Old Way:** Metadata (Model Lineage, Registry Data) was stored in local SQLite files. This was fragile and could not scale.
 * **The New Way:** Production components (Model Registry, Llama Stack) now **require external databases** (MySQL or PostgreSQL).
 * **The Outcome:** This allows your "Factory" to track thousands of model versions and artifacts without performance degradation, utilizing a proper database engine rather than a flat file.

*Now that you understand the blueprint, let's pick up the tools. In the next module, we will deploy this entire architecture using GitOps.*